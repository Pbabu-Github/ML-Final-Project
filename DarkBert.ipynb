{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Imports:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# If running for the first time, install required libraries:\n",
    "%pip install -q datasets transformers evaluate kagglehub python-dotenv hf_xet 'accelerate>=0.26.0'\n",
    "\n",
    "# Load .env variables (requires python-dotenv)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # looks for a .env in our project root, which should have the token key\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"Please set HUGGINGFACE_TOKEN in your environment or .env file.\")\n",
    "\n",
    "# Core Imports & Helpers:\n",
    "import zipfile, shutil, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, ClassLabel\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "# Globals\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading & Pre-processing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['__key__', '__url__', 'txt'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n",
      "Sample rows:\n",
      "                                              __key__  \\\n",
      "0  coda_dataset/5756-Arms-en-06dd9c0e9b321cb78e64...   \n",
      "1  coda_dataset/4055-Financial-en-8d378a316398604...   \n",
      "2  coda_dataset/7429-Financial-en-b41c020ccf19dba...   \n",
      "3  coda_dataset/583-Others-ru-55aa3ecc54ee4f71c6e...   \n",
      "4  coda_dataset/7930-Gambling-en-97540ec78721c815...   \n",
      "\n",
      "                                             __url__  \\\n",
      "0  /Users/blank/.cache/huggingface/hub/datasets--...   \n",
      "1  /Users/blank/.cache/huggingface/hub/datasets--...   \n",
      "2  /Users/blank/.cache/huggingface/hub/datasets--...   \n",
      "3  /Users/blank/.cache/huggingface/hub/datasets--...   \n",
      "4  /Users/blank/.cache/huggingface/hub/datasets--...   \n",
      "\n",
      "                                                 txt  \n",
      "0  search torrents | browse torrents | recent tor...  \n",
      "1  \\n \\n \\n cc cards / buy western union / best p...  \n",
      "2  ru\\nen\\nclub2crd > [en] international forum\\ns...  \n",
      "3  \\n \\n \\n av-check - проверка файлов на вирусы ...  \n",
      "4  intel exchange quick&dirty read-only mirror: t...  \n",
      "Saved train.csv → data_coda\n",
      "Reloaded DataFrame shape: (10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__key__</th>\n",
       "      <th>__url__</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coda_dataset/5756-Arms-en-06dd9c0e9b321cb78e64...</td>\n",
       "      <td>/Users/blank/.cache/huggingface/hub/datasets--...</td>\n",
       "      <td>search torrents | browse torrents | recent tor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coda_dataset/4055-Financial-en-8d378a316398604...</td>\n",
       "      <td>/Users/blank/.cache/huggingface/hub/datasets--...</td>\n",
       "      <td>\\n \\n \\n cc cards / buy western union / best p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coda_dataset/7429-Financial-en-b41c020ccf19dba...</td>\n",
       "      <td>/Users/blank/.cache/huggingface/hub/datasets--...</td>\n",
       "      <td>ru\\nen\\nclub2crd &gt; [en] international forum\\ns...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             __key__  \\\n",
       "0  coda_dataset/5756-Arms-en-06dd9c0e9b321cb78e64...   \n",
       "1  coda_dataset/4055-Financial-en-8d378a316398604...   \n",
       "2  coda_dataset/7429-Financial-en-b41c020ccf19dba...   \n",
       "\n",
       "                                             __url__  \\\n",
       "0  /Users/blank/.cache/huggingface/hub/datasets--...   \n",
       "1  /Users/blank/.cache/huggingface/hub/datasets--...   \n",
       "2  /Users/blank/.cache/huggingface/hub/datasets--...   \n",
       "\n",
       "                                                 txt  \n",
       "0  search torrents | browse torrents | recent tor...  \n",
       "1  \\n \\n \\n cc cards / buy western union / best p...  \n",
       "2  ru\\nen\\nclub2crd > [en] international forum\\ns...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load CoDA once, using the token\n",
    "dataset = load_dataset(\"s2w-ai/CoDA\", token=HF_TOKEN)\n",
    "print(dataset)   # train/validation/test splits not yet defined\n",
    "\n",
    "# convert train split to pandas, save to CSV, reload\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "print(\"Sample rows:\\n\", df.head())\n",
    "\n",
    "data_dir = Path(\"data_coda\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "df.to_csv(data_dir / \"train.csv\", index=False)\n",
    "print(\"Saved train.csv →\", data_dir)\n",
    "\n",
    "# read it back, and use it:\n",
    "csv_file = next(data_dir.glob(\"*.csv\"))\n",
    "df_raw = pd.read_csv(csv_file, encoding=\"latin1\")\n",
    "print(f\"Reloaded DataFrame shape: {df_raw.shape}\")\n",
    "df_raw.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows: 10,000\n",
      "Rows with empty text after basic cleaning: 23\n",
      "Dropped 23 empty rows in total.\n",
      "\n",
      "Token-count summary (before vs after stop-word stage):\n",
      "        tok_before_sw  tok_after_sw\n",
      "count         9977.00       9977.00\n",
      "mean          1195.56       1195.56\n",
      "std           2252.40       2252.40\n",
      "min              1.00          1.00\n",
      "25%            108.00        108.00\n",
      "median         381.00        381.00\n",
      "75%           1059.00       1059.00\n",
      "max          24258.00      24258.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search torrents browse torrents recent torrent...</td>\n",
       "      <td>Arms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cc cards buy western union best paypal cards b...</td>\n",
       "      <td>Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ru en club crd en international forum search a...</td>\n",
       "      <td>Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>av check av check av check ip api av check av ...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intel exchange quick dirty read only mirror to...</td>\n",
       "      <td>Gambling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt      label\n",
       "0  search torrents browse torrents recent torrent...       Arms\n",
       "1  cc cards buy western union best paypal cards b...  Financial\n",
       "2  ru en club crd en international forum search a...  Financial\n",
       "3  av check av check av check ip api av check av ...     Others\n",
       "4  intel exchange quick dirty read only mirror to...   Gambling"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inline Preprocessing & Label Extraction\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Make a working copy so the original stays intact\n",
    "df_clean = df_raw.copy()\n",
    "print(f\"Initial rows: {len(df_clean):,}\")\n",
    "\n",
    "# basic text cleaning\n",
    "df_clean[\"txt\"] = (\n",
    "    df_clean[\"txt\"]\n",
    "        .astype(str)                                        # ensure string\n",
    "        .str.lower()                                        # lowercase\n",
    "        .str.replace(r'<[^>]+>', ' ', regex=True)           # drop HTML tags\n",
    "        .str.replace(r'http\\S+|www\\.\\S+', ' ', regex=True)  # remove URLs\n",
    "        .str.replace(r'[^a-z0-9\\s]', ' ', regex=True)       # keep alphanum\n",
    "        .str.replace(r'\\d+', ' ', regex=True)               # remove digits\n",
    "        .str.replace(r'\\s+', ' ', regex=True)               # collapse spaces\n",
    "        .str.strip()\n",
    ")\n",
    "\n",
    "# Token count BEFORE any stop-word filtering\n",
    "df_clean[\"tok_before_sw\"] = df_clean[\"txt\"].str.count(' ') + 1\n",
    "\n",
    "empty_after_clean = (df_clean[\"txt\"] == \"\").sum()\n",
    "print(f\"Rows with empty text after basic cleaning: {empty_after_clean:,}\")\n",
    "\n",
    "# OPTIONAL: stop-word removal \n",
    "REMOVE_STOPWORDS = False   # Set it to True if you want to drop them\n",
    "if REMOVE_STOPWORDS:\n",
    "    stops = set(ENGLISH_STOP_WORDS)\n",
    "    df_clean[\"txt\"] = df_clean[\"txt\"].apply(\n",
    "        lambda s: ' '.join([w for w in s.split() if w not in stops and len(w) > 2])\n",
    "    )\n",
    "\n",
    "# Token count AFTER\n",
    "df_clean[\"tok_after_sw\"] = df_clean[\"txt\"].str.count(' ') + 1\n",
    "\n",
    "# Drop rows that became empty at any point\n",
    "pre_drop = len(df_clean)\n",
    "df_clean = df_clean[df_clean[\"txt\"].str.len() > 0]\n",
    "print(f\"Dropped {pre_drop - len(df_clean):,} empty rows in total.\")\n",
    "\n",
    "# extract label from __key__\n",
    "df_clean[\"label\"] = df_clean[\"__key__\"].str.split(\"-\", expand=True)[1]\n",
    "\n",
    "# quick summary statistics\n",
    "summary = (\n",
    "    df_clean[[\"tok_before_sw\", \"tok_after_sw\"]]\n",
    "    .describe()\n",
    "    .rename(index={\"50%\": \"median\"})\n",
    "    .round(2)\n",
    ")\n",
    "print(\"\\nToken-count summary (before vs after stop-word stage):\")\n",
    "print(summary)\n",
    "\n",
    "# peek at a few cleaned rows\n",
    "df_clean[[\"txt\", \"label\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 9977/9977 [00:00<00:00, 270326.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['txt', 'label'],\n",
      "        num_rows: 5985\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['txt', 'label'],\n",
      "        num_rows: 1996\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['txt', 'label'],\n",
      "        num_rows: 1996\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Split & cast the cleaned data into a Hugging Face DatasetDict\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n",
    "\n",
    "# keep only the fields we need\n",
    "hf_df = df_clean[[\"txt\", \"label\"]].reset_index(drop=True)\n",
    "\n",
    "# convert to a Dataset\n",
    "full = Dataset.from_pandas(hf_df, preserve_index=False)\n",
    "\n",
    "# cast labels to a ClassLabel feature\n",
    "label_names = sorted(full.unique(\"label\"))\n",
    "full = full.cast_column(\"label\", ClassLabel(names=label_names))\n",
    "\n",
    "# 60/20/20 stratified split\n",
    "split1 = full.train_test_split(test_size=0.2, stratify_by_column=\"label\", seed=457)\n",
    "train_val, test_ds = split1[\"train\"], split1[\"test\"]\n",
    "\n",
    "split2 = train_val.train_test_split(test_size=0.25, stratify_by_column=\"label\", seed=457)\n",
    "train_ds, val_ds = split2[\"train\"], split2[\"test\"]\n",
    "\n",
    "coda = DatasetDict({\"train\": train_ds, \"validation\": val_ds, \"test\": test_ds})\n",
    "print(coda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93        30\n",
      "           1       0.85      0.72      0.78        39\n",
      "           2       0.91      0.86      0.88        57\n",
      "           3       0.94      0.81      0.87        21\n",
      "           4       0.80      0.82      0.81        50\n",
      "           5       1.00      0.93      0.96        40\n",
      "           6       1.00      0.56      0.72        32\n",
      "           7       0.70      0.96      0.81       142\n",
      "           8       1.00      0.75      0.85        63\n",
      "           9       1.00      0.73      0.84        26\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.92      0.80      0.85       500\n",
      "weighted avg       0.87      0.84      0.84       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Quick Sklearn Baseline\n",
    "\n",
    "# tiny train/dev slice\n",
    "small = pd.DataFrame({\n",
    "    \"txt\": train_ds[\"txt\"][:2500],\n",
    "    \"label\": train_ds[\"label\"][:2500]\n",
    "})\n",
    "X_tr, X_dev, y_tr, y_dev = train_test_split(\n",
    "    small[\"txt\"], small[\"label\"], stratify=small[\"label\"], test_size=0.2, random_state=457\n",
    ")\n",
    "\n",
    "# TfidfVectorizer:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(max_features=5000)),(\"clf\", LogisticRegression(max_iter=25000))])\n",
    "\n",
    "pipe.fit(X_tr, y_tr)\n",
    "print(classification_report(y_dev, pipe.predict(X_dev)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusable train/eval function\n",
    "### Using Vanilla Bert as baseline model, to compare to Dark Bert Model along with Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Helper: train + test any transformer on the global `coda` data\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np, pandas as pd, random, torch\n",
    "\n",
    "def compute_metrics_fn(eval_pred):\n",
    "    \"\"\"Return accuracy, macro-F1, micro-F1.\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\"),\n",
    "    }\n",
    "\n",
    "def run_experiment(model_name: str, epochs: int = 3, seed: int = 457):\n",
    "    \"\"\"Train & evaluate one model; return dict with eval_* keys.\"\"\"\n",
    "\n",
    "    # reproducibility\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # tokenise\n",
    "    tok = AutoTokenizer.from_pretrained(model_name, use_auth_token=HF_TOKEN, model_max_length=512)\n",
    "    tok_ds = coda.map(lambda ex: tok(ex[\"txt\"], truncation=True, padding=\"max_length\"),\n",
    "                      batched=True).with_format(\"torch\")\n",
    "\n",
    "    # model\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=len(label_names), use_auth_token=HF_TOKEN\n",
    "    )\n",
    "\n",
    "    #  minimal TrainingArguments (no evaluation_strategy/save_strategy)\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"results/{model_name.replace('/','_')}\",\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=epochs,\n",
    "        learning_rate=5e-5,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    # trainer\n",
    "    trainer = Trainer(\n",
    "        model=mdl,\n",
    "        args=args,\n",
    "        train_dataset=tok_ds[\"train\"],\n",
    "        eval_dataset=tok_ds[\"validation\"],\n",
    "        tokenizer=tok,\n",
    "        compute_metrics=compute_metrics_fn,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    res = trainer.evaluate(tok_ds[\"test\"])   # keys are prefixed with \"eval_\"\n",
    "    return {k: round(v, 4) for k, v in res.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run BERT, RoBERTa, DarkBERT (optional epoch sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training BERT-base …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5985/5985 [00:06<00:00, 883.67 examples/s]\n",
      "Map: 100%|██████████| 1996/1996 [00:01<00:00, 1032.60 examples/s]\n",
      "Map: 100%|██████████| 1996/1996 [00:02<00:00, 849.84 examples/s] \n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='2247' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/2247 00:06 < 3:53:58, 0.16 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mname, label \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m …\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     main_results[label] \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m results_df \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     15\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame(main_results)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     16\u001b[0m       \u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m       })[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_micro\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Test-set metrics (3 epochs) ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 60\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model_name, epochs, seed)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# trainer\u001b[39;00m\n\u001b[1;32m     51\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     52\u001b[0m     model\u001b[38;5;241m=\u001b[39mmdl,\n\u001b[1;32m     53\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics_fn,\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 60\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m res \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(tok_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])   \u001b[38;5;66;03m# keys are prefixed with \"eval_\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[38;5;28mround\u001b[39m(v, \u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m res\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ml-045/lib/python3.9/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ml-045/lib/python3.9/site-packages/transformers/trainer.py:2562\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m-> 2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2566\u001b[0m ):\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#  Main comparison (3 epochs each)\n",
    "\n",
    "models = {\n",
    "    \"bert-base-uncased\": \"BERT-base\",\n",
    "    \"roberta-base\":      \"RoBERTa-base\",   # keep or remove as desired\n",
    "    \"s2w-ai/DarkBERT\":   \"DarkBERT\",\n",
    "}\n",
    "\n",
    "main_results = {}\n",
    "for mname, label in models.items():\n",
    "    print(f\"\\n Training {label} …\")\n",
    "    main_results[label] = run_experiment(mname, epochs=3)\n",
    "\n",
    "results_df = (\n",
    "    pd.DataFrame(main_results).T\n",
    "      .rename(columns={\n",
    "          \"eval_accuracy\": \"accuracy\",\n",
    "          \"eval_f1_macro\": \"f1_macro\",\n",
    "          \"eval_f1_micro\": \"f1_micro\"\n",
    "      })[[\"accuracy\", \"f1_macro\", \"f1_micro\"]]\n",
    ")\n",
    "\n",
    "print(\"\\n=== Test-set metrics (3 epochs) ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  OPTIONAL: sweep epochs to see how the gap changes\n",
    "\n",
    "epochs_to_try = [3, 5, 8, 10, 12]\n",
    "sweep_metrics = [\"f1_macro\", \"accuracy\"]   # choose the metrics you care about\n",
    "\n",
    "def sweep(model_name, label):\n",
    "    table = {}\n",
    "    for e in epochs_to_try:\n",
    "        print(f\"\\n {label} | {e} epochs\")\n",
    "        res = run_experiment(model_name, epochs=e)\n",
    "        table[e] = {m: res[f\"eval_{m}\"] for m in sweep_metrics}\n",
    "    return pd.DataFrame(table).T\n",
    "\n",
    "# Run sweeps\n",
    "bert_sweep  = sweep(\"bert-base-uncased\", \"BERT-base\")\n",
    "dark_sweep  = sweep(\"s2w-ai/DarkBERT\",  \"DarkBERT\")\n",
    "\n",
    "print(\"\\n=== BERT-base: metric vs epochs ===\")\n",
    "display(bert_sweep)\n",
    "\n",
    "print(\"\\n=== DarkBERT: metric vs epochs ===\")\n",
    "display(dark_sweep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-045",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
